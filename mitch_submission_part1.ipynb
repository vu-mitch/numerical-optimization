{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8dac0371-3be8-4fc9-a99a-1c00d26d787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "def problem(dim):\n",
    "    dim = dim\n",
    "    x_solution = torch.randint(low=1, high=9, size=(dim, 1)).type(torch.DoubleTensor)\n",
    "\n",
    "    # A must be symmetric, therefore we multiply it with its transpose\n",
    "    A = torch.randint(low=1, high=9, size=(dim, dim)).type(torch.DoubleTensor)\n",
    "    A = A @ A.T\n",
    "    b = A @ x_solution\n",
    "\n",
    "    return x_solution, A, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7bbb32ec-f4c9-444f-804f-6d79a8c84831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function\n",
    "def f(x, A, b):\n",
    "    return (1/2) * x.T @ A @ x - b.T @ x\n",
    "\n",
    "def f_grad(x, A, b):\n",
    "    return A@x - b\n",
    "\n",
    "def f_hessian(x, A, b):\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8408189f-32b7-48e8-8ad5-c5f14e1cb07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_search(f, x, p, grad, alpha=1, r=0.8, c=0.9):\n",
    "  # backtracking algortihm from page 37\n",
    "\n",
    "    while f(x + alpha * p) > f(x) + (c * alpha * grad(x).T @ p):\n",
    "        alpha = r * alpha\n",
    "\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8ccd8bc4-4f91-41cf-b272-872335ded6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# Steepest Descent   #\n",
    "######################\n",
    "\n",
    "def steepest_descent(A, b):\n",
    "    initial_vector = torch.randint(low=1, high=9, size=(dim, 1)).type(torch.DoubleTensor)\n",
    "    \n",
    "    # set lambda functions\n",
    "    f_lambda = lambda x: f(x, A, b)\n",
    "    f_grad_lambda = lambda x: f_grad(x, A, b)\n",
    "\n",
    "    # set parameters\n",
    "    stopp = 0.1\n",
    "    loss = 1000\n",
    "    i = 0\n",
    "\n",
    "    # set initial values\n",
    "    x = initial_vector\n",
    "\n",
    "    while loss > stopp:\n",
    "        p = -1 * f_grad_lambda(x)\n",
    "        alpha = line_search(f_lambda, x, p, f_grad_lambda)\n",
    "\n",
    "        x_next = x + alpha * p\n",
    "        loss = torch.norm(f_grad_lambda(x_next), p=2)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f'iteration:[{i}] Loss: {round(loss.item(), 2)}')\n",
    "\n",
    "        x = x_next\n",
    "        i+=1\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8552de47-2e87-48a8-9895-a03a1155bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# Newton Method      #\n",
    "######################\n",
    "\n",
    "def newton_method(A, b):\n",
    "    initial_vec = torch.randint(low=1, high=9, size=(dim, 1)).type(torch.DoubleTensor)\n",
    "    \n",
    "    # set lambda functions\n",
    "    f_lambda = lambda x: f(x, A, b)\n",
    "    f_grad_lambda = lambda x: f_grad(x, A, b)\n",
    "    f_hessian_lambda = lambda x: f_hessian(x, A, b)\n",
    "\n",
    "    # set parameters\n",
    "    stopp = 0.1\n",
    "    loss = 1000\n",
    "    i = 0\n",
    "\n",
    "    # set initial values\n",
    "    x = initial_vec\n",
    "    \n",
    "    while loss > stopp:\n",
    "        p = -1 * torch.inverse(f_hessian_lambda(x)) @ f_grad_lambda(x)\n",
    "        alpha = line_search(f_lambda, x, p, f_grad_lambda)\n",
    "\n",
    "        x_next = x + alpha * p\n",
    "        loss = torch.norm(f_grad_lambda(x_next), p=2)\n",
    "\n",
    "        if i % 4 == 0:\n",
    "            print(f'iteration:[{i}] Loss: {round(loss.item(), 2)}')\n",
    "\n",
    "        x = x_next\n",
    "        i+=1\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8cdda663-f539-4a89-9c1b-c4cf98e9d529",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Quasi-Newton Method (BFGS)   #\n",
    "################################\n",
    "\n",
    "def quasi_newton(A,b):\n",
    "    initial_point = torch.randint(low=1, high=9, size=(dim, 1)).type(torch.DoubleTensor)\n",
    "\n",
    "    # set lambda functions\n",
    "    f_lambda = lambda x: f(x, A, b)\n",
    "    f_grad_lambda = lambda x: f_grad(x, A, b)\n",
    "    f_hessian_lambda = lambda x: f_hessian(x, A, b)\n",
    "\n",
    "    # set parameters\n",
    "    stopp = 0.1\n",
    "    loss = 1000\n",
    "    i = 0\n",
    "\n",
    "    # set initial values\n",
    "    x = initial_point\n",
    "    grad = f_grad_lambda(x)\n",
    "    I = torch.eye(dim).type(torch.DoubleTensor)\n",
    "    H = torch.clone(I)\n",
    "\n",
    "    while loss > stopp:\n",
    "        p = -1 * H @ grad\n",
    "        alpha = line_search(f_lambda, x, p, f_grad_lambda)\n",
    "\n",
    "        x_next = x + alpha * p\n",
    "        grad_next = f_grad_lambda(x_next)\n",
    "\n",
    "        # BFGS Method 6.1\n",
    "        s = x_next - x          # 6.5\n",
    "        y = grad_next - grad    # 6.5\n",
    "        r = 1 / (y.T @ s)       # 6.14\n",
    "        H_next = (I - r*s@y.T) @ H @ (I - r*y@s.T) + r*s@s.T   # 6.17\n",
    "\n",
    "        loss = torch.norm(f_grad_lambda(x_next), p=2)\n",
    "\n",
    "        if i % 4 == 0:\n",
    "            print(f'[{i}] Loss: {round(loss.item(), 2)}')\n",
    "\n",
    "        x = x_next\n",
    "        grad = grad_next\n",
    "        H = H_next\n",
    "        i+=1\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6a12a859-ab4d-40ca-a67f-2fc5857d4249",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Conjugate Gradient Method    #\n",
    "################################\n",
    "\n",
    "def conjugate_gradient(A,b):\n",
    "    initial_point = torch.randint(low=1, high=9, size=(dim, 1)).type(torch.DoubleTensor)\n",
    "\n",
    "    # set lambda functions\n",
    "    f_lambda = lambda x: f(x, A, b)\n",
    "    f_grad_lambda = lambda x: f_grad(x, A, b)\n",
    "    f_hessian_lambda = lambda x: f_hessian(x, A, b)\n",
    "\n",
    "    # set parameters\n",
    "    stopp = 0.1\n",
    "    loss = 1000\n",
    "    i = 0\n",
    "\n",
    "    # set initial values\n",
    "    x = initial_point\n",
    "    r = f_grad_lambda(x)\n",
    "    p = -r\n",
    "\n",
    "    while loss > stopp:\n",
    "        # Conjugate Gradient Method (CG) 5.2\n",
    "        alpha = (r.T @ r)/(p.T @ A @ p)\n",
    "        x_next = x + alpha * p\n",
    "\n",
    "        r_next = r + alpha * A @ p\n",
    "        beta_next = (r_next.T @ r_next) / (r.T @ r)\n",
    "        p_next = -r_next + beta_next * p\n",
    "\n",
    "        loss = torch.norm(f_grad_lambda(x_next), p=2)\n",
    "\n",
    "        if i % 1 == 0:\n",
    "            print(f'[{i}] Loss: {round(loss.item(), 2)}')\n",
    "\n",
    "        x = x_next\n",
    "        r = r_next\n",
    "        p = p_next\n",
    "        i+=1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042086b4-77e5-4ef6-8efb-b0b2752edbc3",
   "metadata": {},
   "source": [
    "# 1) Matrix 10x10:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "89d0d1c6-a57f-4966-aea6-2ee8c6bb33af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 10\n",
    "x_solution, A, b = problem(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bd9ddc72-f206-479d-9daf-8be586f07802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:[0] Loss: 5881.34\n",
      "iteration:[100] Loss: 9.5\n",
      "iteration:[200] Loss: 4.1\n",
      "iteration:[300] Loss: 1.82\n",
      "iteration:[400] Loss: 1.0\n",
      "iteration:[500] Loss: 0.57\n",
      "iteration:[600] Loss: 0.4\n",
      "iteration:[700] Loss: 0.25\n",
      "iteration:[800] Loss: 0.15\n"
     ]
    }
   ],
   "source": [
    "x1 = steepest_descent(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4e8708aa-fbec-4e79-8d95-e134d68d5435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:[0] Loss: 864.42\n",
      "iteration:[4] Loss: 414.66\n",
      "iteration:[8] Loss: 198.91\n",
      "iteration:[12] Loss: 95.42\n",
      "iteration:[16] Loss: 45.77\n",
      "iteration:[20] Loss: 21.96\n",
      "iteration:[24] Loss: 10.53\n",
      "iteration:[28] Loss: 5.05\n",
      "iteration:[32] Loss: 2.42\n",
      "iteration:[36] Loss: 1.16\n",
      "iteration:[40] Loss: 0.56\n",
      "iteration:[44] Loss: 0.27\n",
      "iteration:[48] Loss: 0.13\n"
     ]
    }
   ],
   "source": [
    "x2 = newton_method(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d8660182-370d-4468-9bdd-828b90cea193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Loss: 277.46\n",
      "[4] Loss: 228.35\n",
      "[8] Loss: 181.57\n",
      "[12] Loss: 93.61\n",
      "[16] Loss: 44.84\n",
      "[20] Loss: 21.51\n",
      "[24] Loss: 10.32\n",
      "[28] Loss: 4.95\n",
      "[32] Loss: 2.37\n",
      "[36] Loss: 1.14\n",
      "[40] Loss: 0.55\n",
      "[44] Loss: 0.26\n",
      "[48] Loss: 0.13\n"
     ]
    }
   ],
   "source": [
    "x3 = quasi_newton(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4c71e448-b6c3-465d-a9b2-2eca565a1ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Loss: 665.17\n",
      "[1] Loss: 162.08\n",
      "[2] Loss: 86.5\n",
      "[3] Loss: 17.44\n",
      "[4] Loss: 28.25\n",
      "[5] Loss: 5.61\n",
      "[6] Loss: 7.44\n",
      "[7] Loss: 4.87\n",
      "[8] Loss: 5.41\n",
      "[9] Loss: 4.8\n",
      "[10] Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "x4 = conjugate_gradient(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5affc9f6-07b4-466d-a7c7-e478f98bc8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solution</th>\n",
       "      <th>steepest_descent</th>\n",
       "      <th>newton_method</th>\n",
       "      <th>quasi_newton</th>\n",
       "      <th>conjugate_gradient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.023978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.001900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.000552</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.998470</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.971998</td>\n",
       "      <td>5.999658</td>\n",
       "      <td>6.000257</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.020186</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000968</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.994415</td>\n",
       "      <td>6.999572</td>\n",
       "      <td>6.998138</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.011785</td>\n",
       "      <td>1.000342</td>\n",
       "      <td>1.001895</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.967117</td>\n",
       "      <td>3.000257</td>\n",
       "      <td>2.999623</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.997116</td>\n",
       "      <td>3.000428</td>\n",
       "      <td>2.999675</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.011894</td>\n",
       "      <td>2.000428</td>\n",
       "      <td>2.000327</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.998479</td>\n",
       "      <td>6.999658</td>\n",
       "      <td>6.999373</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   solution  steepest_descent  newton_method  quasi_newton  conjugate_gradient\n",
       "0       1.0          1.023978       1.000000      1.001900                 1.0\n",
       "1       6.0          6.000552       6.000000      5.998470                 6.0\n",
       "2       6.0          5.971998       5.999658      6.000257                 6.0\n",
       "3       4.0          4.020186       4.000000      4.000968                 4.0\n",
       "4       7.0          6.994415       6.999572      6.998138                 7.0\n",
       "5       1.0          1.011785       1.000342      1.001895                 1.0\n",
       "6       3.0          2.967117       3.000257      2.999623                 3.0\n",
       "7       3.0          2.997116       3.000428      2.999675                 3.0\n",
       "8       2.0          2.011894       2.000428      2.000327                 2.0\n",
       "9       7.0          6.998479       6.999658      6.999373                 7.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"solution\":x_solution.flatten(),\"steepest_descent\":x1.flatten(),\"newton_method\":x2.flatten(),\"quasi_newton\":x3.flatten(),\"conjugate_gradient\":x4.flatten()}\n",
    "pd.DataFrame(data,columns=[\"solution\",\"steepest_descent\",\"newton_method\",\"quasi_newton\",\"conjugate_gradient\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d8a62c-048e-453a-81ba-95397e119c95",
   "metadata": {},
   "source": [
    "# 2) Matrix 20x20:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e2c71c65-7067-45c1-addf-fcc99aaa3f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 20\n",
    "x_solution, A, b = problem(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e858f54e-950f-437c-a883-b2d44eabffe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:[0] Loss: 2085.24\n",
      "iteration:[100] Loss: 42.27\n",
      "iteration:[200] Loss: 14.22\n",
      "iteration:[300] Loss: 12.94\n",
      "iteration:[400] Loss: 3.24\n",
      "iteration:[500] Loss: 3.7\n",
      "iteration:[600] Loss: 2.86\n",
      "iteration:[700] Loss: 2.4\n",
      "iteration:[800] Loss: 6.88\n",
      "iteration:[900] Loss: 5.34\n",
      "iteration:[1000] Loss: 4.01\n",
      "iteration:[1100] Loss: 4.02\n",
      "iteration:[1200] Loss: 3.06\n",
      "iteration:[1300] Loss: 2.4\n",
      "iteration:[1400] Loss: 1.88\n",
      "iteration:[1500] Loss: 1.4\n",
      "iteration:[1600] Loss: 1.27\n",
      "iteration:[1700] Loss: 3.56\n",
      "iteration:[1800] Loss: 2.77\n",
      "iteration:[1900] Loss: 2.79\n",
      "iteration:[2000] Loss: 2.09\n",
      "iteration:[2100] Loss: 1.24\n",
      "iteration:[2200] Loss: 1.27\n",
      "iteration:[2300] Loss: 1.0\n",
      "iteration:[2400] Loss: 0.79\n",
      "iteration:[2500] Loss: 0.67\n",
      "iteration:[2600] Loss: 1.94\n",
      "iteration:[2700] Loss: 0.59\n",
      "iteration:[2800] Loss: 1.16\n",
      "iteration:[2900] Loss: 0.92\n",
      "iteration:[3000] Loss: 0.91\n",
      "iteration:[3100] Loss: 0.73\n",
      "iteration:[3200] Loss: 0.59\n",
      "iteration:[3300] Loss: 0.47\n",
      "iteration:[3400] Loss: 0.42\n",
      "iteration:[3500] Loss: 1.21\n",
      "iteration:[3600] Loss: 1.26\n",
      "iteration:[3700] Loss: 1.0\n",
      "iteration:[3800] Loss: 0.79\n",
      "iteration:[3900] Loss: 0.48\n",
      "iteration:[4000] Loss: 0.39\n",
      "iteration:[4100] Loss: 0.42\n",
      "iteration:[4200] Loss: 0.38\n",
      "iteration:[4300] Loss: 0.4\n",
      "iteration:[4400] Loss: 0.33\n",
      "iteration:[4500] Loss: 0.29\n",
      "iteration:[4600] Loss: 0.33\n",
      "iteration:[4700] Loss: 0.73\n",
      "iteration:[4800] Loss: 0.78\n",
      "iteration:[4900] Loss: 0.61\n",
      "iteration:[5000] Loss: 0.75\n",
      "iteration:[5100] Loss: 0.46\n",
      "iteration:[5200] Loss: 0.74\n",
      "iteration:[5300] Loss: 0.26\n",
      "iteration:[5400] Loss: 0.71\n",
      "iteration:[5500] Loss: 0.66\n",
      "iteration:[5600] Loss: 1.02\n",
      "iteration:[5700] Loss: 0.25\n",
      "iteration:[5800] Loss: 0.28\n",
      "iteration:[5900] Loss: 0.82\n",
      "iteration:[6000] Loss: 0.51\n",
      "iteration:[6100] Loss: 0.63\n",
      "iteration:[6200] Loss: 0.24\n",
      "iteration:[6300] Loss: 0.24\n",
      "iteration:[6400] Loss: 0.65\n",
      "iteration:[6500] Loss: 0.51\n",
      "iteration:[6600] Loss: 0.48\n",
      "iteration:[6700] Loss: 0.51\n",
      "iteration:[6800] Loss: 0.63\n",
      "iteration:[6900] Loss: 0.5\n",
      "iteration:[7000] Loss: 0.31\n",
      "iteration:[7100] Loss: 0.38\n",
      "iteration:[7200] Loss: 0.4\n",
      "iteration:[7300] Loss: 0.33\n",
      "iteration:[7400] Loss: 0.27\n",
      "iteration:[7500] Loss: 0.37\n",
      "iteration:[7600] Loss: 0.59\n",
      "iteration:[7700] Loss: 0.54\n",
      "iteration:[7800] Loss: 0.23\n",
      "iteration:[7900] Loss: 0.52\n",
      "iteration:[8000] Loss: 0.56\n",
      "iteration:[8100] Loss: 0.34\n",
      "iteration:[8200] Loss: 0.36\n",
      "iteration:[8300] Loss: 0.23\n",
      "iteration:[8400] Loss: 0.24\n",
      "iteration:[8500] Loss: 0.43\n",
      "iteration:[8600] Loss: 0.27\n",
      "iteration:[8700] Loss: 0.42\n",
      "iteration:[8800] Loss: 0.52\n",
      "iteration:[8900] Loss: 0.18\n",
      "iteration:[9000] Loss: 0.56\n",
      "iteration:[9100] Loss: 0.18\n",
      "iteration:[9200] Loss: 0.2\n",
      "iteration:[9300] Loss: 0.18\n",
      "iteration:[9400] Loss: 0.18\n",
      "iteration:[9500] Loss: 0.18\n",
      "iteration:[9600] Loss: 0.21\n",
      "iteration:[9700] Loss: 0.23\n",
      "iteration:[9800] Loss: 0.25\n",
      "iteration:[9900] Loss: 0.31\n",
      "iteration:[10000] Loss: 0.38\n",
      "iteration:[10100] Loss: 0.3\n",
      "iteration:[10200] Loss: 0.28\n",
      "iteration:[10300] Loss: 0.3\n",
      "iteration:[10400] Loss: 0.36\n",
      "iteration:[10500] Loss: 0.29\n",
      "iteration:[10600] Loss: 0.24\n",
      "iteration:[10700] Loss: 0.22\n",
      "iteration:[10800] Loss: 0.41\n",
      "iteration:[10900] Loss: 0.43\n",
      "iteration:[11000] Loss: 0.15\n",
      "iteration:[11100] Loss: 0.42\n",
      "iteration:[11200] Loss: 0.33\n",
      "iteration:[11300] Loss: 0.17\n",
      "iteration:[11400] Loss: 0.2\n",
      "iteration:[11500] Loss: 0.31\n",
      "iteration:[11600] Loss: 0.38\n",
      "iteration:[11700] Loss: 0.15\n",
      "iteration:[11800] Loss: 0.15\n",
      "iteration:[11900] Loss: 0.19\n",
      "iteration:[12000] Loss: 0.17\n",
      "iteration:[12100] Loss: 0.26\n",
      "iteration:[12200] Loss: 0.14\n",
      "iteration:[12300] Loss: 0.17\n",
      "iteration:[12400] Loss: 0.32\n",
      "iteration:[12500] Loss: 0.13\n",
      "iteration:[12600] Loss: 0.54\n",
      "iteration:[12700] Loss: 0.13\n",
      "iteration:[12800] Loss: 0.27\n",
      "iteration:[12900] Loss: 0.29\n",
      "iteration:[13000] Loss: 0.36\n",
      "iteration:[13100] Loss: 0.13\n",
      "iteration:[13200] Loss: 0.26\n",
      "iteration:[13300] Loss: 0.12\n",
      "iteration:[13400] Loss: 0.5\n",
      "iteration:[13500] Loss: 0.14\n",
      "iteration:[13600] Loss: 0.22\n",
      "iteration:[13700] Loss: 0.21\n",
      "iteration:[13800] Loss: 0.12\n",
      "iteration:[13900] Loss: 0.12\n",
      "iteration:[14000] Loss: 0.12\n",
      "iteration:[14100] Loss: 0.23\n",
      "iteration:[14200] Loss: 0.13\n",
      "iteration:[14300] Loss: 0.12\n",
      "iteration:[14400] Loss: 0.12\n",
      "iteration:[14500] Loss: 0.19\n",
      "iteration:[14600] Loss: 0.31\n",
      "iteration:[14700] Loss: 0.23\n",
      "iteration:[14800] Loss: 0.41\n",
      "iteration:[14900] Loss: 0.11\n",
      "iteration:[15000] Loss: 0.3\n",
      "iteration:[15100] Loss: 0.36\n",
      "iteration:[15200] Loss: 0.42\n",
      "iteration:[15300] Loss: 0.28\n",
      "iteration:[15400] Loss: 0.19\n",
      "iteration:[15500] Loss: 0.27\n",
      "iteration:[15600] Loss: 0.22\n",
      "iteration:[15700] Loss: 0.34\n",
      "iteration:[15800] Loss: 0.31\n"
     ]
    }
   ],
   "source": [
    "x1 = steepest_descent(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "33894a25-bbae-4109-b79f-02a8a1d9b123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:[0] Loss: 32709.66\n",
      "iteration:[4] Loss: 15690.8\n",
      "iteration:[8] Loss: 7526.86\n",
      "iteration:[12] Loss: 3610.63\n",
      "iteration:[16] Loss: 1732.02\n",
      "iteration:[20] Loss: 830.85\n",
      "iteration:[24] Loss: 398.56\n",
      "iteration:[28] Loss: 191.19\n",
      "iteration:[32] Loss: 91.71\n",
      "iteration:[36] Loss: 43.99\n",
      "iteration:[40] Loss: 21.1\n",
      "iteration:[44] Loss: 10.12\n",
      "iteration:[48] Loss: 4.86\n",
      "iteration:[52] Loss: 2.33\n",
      "iteration:[56] Loss: 1.12\n",
      "iteration:[60] Loss: 0.54\n",
      "iteration:[64] Loss: 0.26\n",
      "iteration:[68] Loss: 0.12\n"
     ]
    }
   ],
   "source": [
    "x2 = newton_method(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1b3e0d1d-e578-442f-b68d-2fbf9469dcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Loss: 23122.12\n",
      "[4] Loss: 22539.94\n",
      "[8] Loss: 19227.8\n",
      "[12] Loss: 17475.65\n",
      "[16] Loss: 14721.4\n",
      "[20] Loss: 11108.36\n",
      "[24] Loss: 5255.76\n",
      "[28] Loss: 2521.17\n",
      "[32] Loss: 1209.39\n",
      "[36] Loss: 580.13\n",
      "[40] Loss: 278.28\n",
      "[44] Loss: 133.48\n",
      "[48] Loss: 64.02\n",
      "[52] Loss: 30.7\n",
      "[56] Loss: 14.72\n",
      "[60] Loss: 7.05\n",
      "[64] Loss: 3.38\n",
      "[68] Loss: 1.61\n",
      "[72] Loss: 0.77\n",
      "[76] Loss: 0.36\n",
      "[80] Loss: 0.17\n"
     ]
    }
   ],
   "source": [
    "x3 = quasi_newton(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aa1a97ea-8ebc-4815-87ac-0751f38e3491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Loss: 2764.24\n",
      "[1] Loss: 575.95\n",
      "[2] Loss: 159.91\n",
      "[3] Loss: 80.08\n",
      "[4] Loss: 53.75\n",
      "[5] Loss: 48.67\n",
      "[6] Loss: 26.66\n",
      "[7] Loss: 17.4\n",
      "[8] Loss: 85.6\n",
      "[9] Loss: 11.92\n",
      "[10] Loss: 11.61\n",
      "[11] Loss: 6.32\n",
      "[12] Loss: 4.0\n",
      "[13] Loss: 3.21\n",
      "[14] Loss: 1.76\n",
      "[15] Loss: 1.25\n",
      "[16] Loss: 2.61\n",
      "[17] Loss: 0.32\n",
      "[18] Loss: 0.74\n",
      "[19] Loss: 1.61\n",
      "[20] Loss: 0.12\n",
      "[21] Loss: 0.18\n",
      "[22] Loss: 0.41\n",
      "[23] Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "x4 = conjugate_gradient(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6df1bc9c-a774-458e-beeb-467ad747a4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solution</th>\n",
       "      <th>steepest_descent</th>\n",
       "      <th>newton_method</th>\n",
       "      <th>quasi_newton</th>\n",
       "      <th>conjugate_gradient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.108826</td>\n",
       "      <td>5.999989</td>\n",
       "      <td>5.999743</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.909642</td>\n",
       "      <td>6.000004</td>\n",
       "      <td>6.000195</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.548070</td>\n",
       "      <td>4.999991</td>\n",
       "      <td>4.998771</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.467225</td>\n",
       "      <td>5.999989</td>\n",
       "      <td>6.001185</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.697877</td>\n",
       "      <td>3.999998</td>\n",
       "      <td>4.000687</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.874845</td>\n",
       "      <td>6.999987</td>\n",
       "      <td>7.000272</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.128218</td>\n",
       "      <td>2.999998</td>\n",
       "      <td>2.999732</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.985897</td>\n",
       "      <td>6.999989</td>\n",
       "      <td>7.000014</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.120174</td>\n",
       "      <td>6.999998</td>\n",
       "      <td>6.999731</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.792840</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000462</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.094918</td>\n",
       "      <td>4.000002</td>\n",
       "      <td>3.999792</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.197216</td>\n",
       "      <td>2.000007</td>\n",
       "      <td>1.999572</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.0</td>\n",
       "      <td>7.952470</td>\n",
       "      <td>7.999993</td>\n",
       "      <td>8.000104</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.139857</td>\n",
       "      <td>5.999991</td>\n",
       "      <td>5.999677</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.127917</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.999736</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.835813</td>\n",
       "      <td>1.000015</td>\n",
       "      <td>1.000369</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.246134</td>\n",
       "      <td>1.000013</td>\n",
       "      <td>0.999476</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.940239</td>\n",
       "      <td>3.999998</td>\n",
       "      <td>4.000135</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.979535</td>\n",
       "      <td>4.999991</td>\n",
       "      <td>5.000055</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.828954</td>\n",
       "      <td>1.999998</td>\n",
       "      <td>2.000402</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    solution  steepest_descent  newton_method  quasi_newton  \\\n",
       "0        6.0          6.108826       5.999989      5.999743   \n",
       "1        6.0          5.909642       6.000004      6.000195   \n",
       "2        5.0          5.548070       4.999991      4.998771   \n",
       "3        6.0          5.467225       5.999989      6.001185   \n",
       "4        4.0          3.697877       3.999998      4.000687   \n",
       "5        7.0          6.874845       6.999987      7.000272   \n",
       "6        3.0          3.128218       2.999998      2.999732   \n",
       "7        7.0          6.985897       6.999989      7.000014   \n",
       "8        7.0          7.120174       6.999998      6.999731   \n",
       "9        6.0          5.792840       6.000000      6.000462   \n",
       "10       4.0          4.094918       4.000002      3.999792   \n",
       "11       2.0          2.197216       2.000007      1.999572   \n",
       "12       8.0          7.952470       7.999993      8.000104   \n",
       "13       6.0          6.139857       5.999991      5.999677   \n",
       "14       2.0          2.127917       2.000000      1.999736   \n",
       "15       1.0          0.835813       1.000015      1.000369   \n",
       "16       1.0          1.246134       1.000013      0.999476   \n",
       "17       4.0          3.940239       3.999998      4.000135   \n",
       "18       5.0          4.979535       4.999991      5.000055   \n",
       "19       2.0          1.828954       1.999998      2.000402   \n",
       "\n",
       "    conjugate_gradient  \n",
       "0                  6.0  \n",
       "1                  6.0  \n",
       "2                  5.0  \n",
       "3                  6.0  \n",
       "4                  4.0  \n",
       "5                  7.0  \n",
       "6                  3.0  \n",
       "7                  7.0  \n",
       "8                  7.0  \n",
       "9                  6.0  \n",
       "10                 4.0  \n",
       "11                 2.0  \n",
       "12                 8.0  \n",
       "13                 6.0  \n",
       "14                 2.0  \n",
       "15                 1.0  \n",
       "16                 1.0  \n",
       "17                 4.0  \n",
       "18                 5.0  \n",
       "19                 2.0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"solution\":x_solution.flatten(),\"steepest_descent\":x1.flatten(),\"newton_method\":x2.flatten(),\"quasi_newton\":x3.flatten(),\"conjugate_gradient\":x4.flatten()}\n",
    "pd.DataFrame(data,columns=[\"solution\",\"steepest_descent\",\"newton_method\",\"quasi_newton\",\"conjugate_gradient\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acd0154-98aa-4482-af45-8c13b3ea16c8",
   "metadata": {},
   "source": [
    "# 3) Matrix 13x13:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6bc978d7-d3b4-46e7-bfbf-c836eb67f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 13\n",
    "x_solution, A, b = problem(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8f7d8ee0-557c-4a88-a977-8f0a971f8713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:[0] Loss: 16824.38\n",
      "iteration:[100] Loss: 12.56\n",
      "iteration:[200] Loss: 1.41\n",
      "iteration:[300] Loss: 1.95\n",
      "iteration:[400] Loss: 1.11\n",
      "iteration:[500] Loss: 0.66\n",
      "iteration:[600] Loss: 2.1\n",
      "iteration:[700] Loss: 1.52\n",
      "iteration:[800] Loss: 1.11\n",
      "iteration:[900] Loss: 0.79\n",
      "iteration:[1000] Loss: 1.05\n",
      "iteration:[1100] Loss: 0.37\n",
      "iteration:[1200] Loss: 0.29\n",
      "iteration:[1300] Loss: 0.82\n",
      "iteration:[1400] Loss: 0.28\n",
      "iteration:[1500] Loss: 0.23\n",
      "iteration:[1600] Loss: 0.25\n",
      "iteration:[1700] Loss: 0.25\n",
      "iteration:[1800] Loss: 0.2\n",
      "iteration:[1900] Loss: 0.15\n",
      "iteration:[2000] Loss: 0.33\n",
      "iteration:[2100] Loss: 0.32\n",
      "iteration:[2200] Loss: 0.36\n",
      "iteration:[2300] Loss: 0.14\n",
      "iteration:[2400] Loss: 0.32\n",
      "iteration:[2500] Loss: 0.28\n"
     ]
    }
   ],
   "source": [
    "x1 = steepest_descent(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "95d05f30-b0d6-4ed6-b4a7-4cd80cb1a470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:[0] Loss: 10959.59\n",
      "iteration:[4] Loss: 5257.3\n",
      "iteration:[8] Loss: 2521.92\n",
      "iteration:[12] Loss: 1209.77\n",
      "iteration:[16] Loss: 580.32\n",
      "iteration:[20] Loss: 278.38\n",
      "iteration:[24] Loss: 133.54\n",
      "iteration:[28] Loss: 64.06\n",
      "iteration:[32] Loss: 30.73\n",
      "iteration:[36] Loss: 14.74\n",
      "iteration:[40] Loss: 7.07\n",
      "iteration:[44] Loss: 3.39\n",
      "iteration:[48] Loss: 1.63\n",
      "iteration:[52] Loss: 0.78\n",
      "iteration:[56] Loss: 0.37\n",
      "iteration:[60] Loss: 0.18\n",
      "iteration:[64] Loss: 0.09\n"
     ]
    }
   ],
   "source": [
    "x2 = newton_method(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b98df68a-1465-4c4a-a182-321807c4ecb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Loss: 8470.38\n",
      "[4] Loss: 7773.74\n",
      "[8] Loss: 6573.2\n",
      "[12] Loss: 4340.26\n",
      "[16] Loss: 2033.15\n",
      "[20] Loss: 970.65\n",
      "[24] Loss: 465.46\n",
      "[28] Loss: 223.26\n",
      "[32] Loss: 107.07\n",
      "[36] Loss: 51.33\n",
      "[40] Loss: 24.57\n",
      "[44] Loss: 11.7\n",
      "[48] Loss: 5.49\n",
      "[52] Loss: 2.46\n",
      "[56] Loss: 0.92\n",
      "[60] Loss: 0.05\n"
     ]
    }
   ],
   "source": [
    "x3 = quasi_newton(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "93d3341f-dda5-4f3f-b316-31a7fd49b9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Loss: 1368.23\n",
      "[1] Loss: 357.5\n",
      "[2] Loss: 157.64\n",
      "[3] Loss: 68.48\n",
      "[4] Loss: 27.99\n",
      "[5] Loss: 23.74\n",
      "[6] Loss: 16.88\n",
      "[7] Loss: 11.0\n",
      "[8] Loss: 11.0\n",
      "[9] Loss: 106.28\n",
      "[10] Loss: 5.24\n",
      "[11] Loss: 0.21\n",
      "[12] Loss: 0.17\n",
      "[13] Loss: 0.02\n"
     ]
    }
   ],
   "source": [
    "x4 = conjugate_gradient(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "26009525-cc7f-47ad-be36-0cd9e6cd66fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solution</th>\n",
       "      <th>steepest_descent</th>\n",
       "      <th>newton_method</th>\n",
       "      <th>quasi_newton</th>\n",
       "      <th>conjugate_gradient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.365166</td>\n",
       "      <td>1.000039</td>\n",
       "      <td>1.051843</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.907617</td>\n",
       "      <td>3.999980</td>\n",
       "      <td>4.014572</td>\n",
       "      <td>3.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.053752</td>\n",
       "      <td>1.000046</td>\n",
       "      <td>0.996193</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.843670</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.011216</td>\n",
       "      <td>6.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.071776</td>\n",
       "      <td>3.000026</td>\n",
       "      <td>2.904901</td>\n",
       "      <td>2.999997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.221355</td>\n",
       "      <td>4.000020</td>\n",
       "      <td>3.979888</td>\n",
       "      <td>3.999997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.851760</td>\n",
       "      <td>5.999980</td>\n",
       "      <td>6.096681</td>\n",
       "      <td>5.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.283840</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>0.974578</td>\n",
       "      <td>0.999997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.456674</td>\n",
       "      <td>7.999967</td>\n",
       "      <td>7.962834</td>\n",
       "      <td>8.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.731718</td>\n",
       "      <td>2.000039</td>\n",
       "      <td>2.025203</td>\n",
       "      <td>2.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.025552</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.999484</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.897942</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.008566</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.364607</td>\n",
       "      <td>6.999967</td>\n",
       "      <td>6.966460</td>\n",
       "      <td>6.999996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    solution  steepest_descent  newton_method  quasi_newton  \\\n",
       "0        1.0          0.365166       1.000039      1.051843   \n",
       "1        4.0          3.907617       3.999980      4.014572   \n",
       "2        1.0          1.053752       1.000046      0.996193   \n",
       "3        7.0          6.843670       7.000000      7.011216   \n",
       "4        3.0          4.071776       3.000026      2.904901   \n",
       "5        4.0          4.221355       4.000020      3.979888   \n",
       "6        6.0          4.851760       5.999980      6.096681   \n",
       "7        1.0          1.283840       1.000026      0.974578   \n",
       "8        8.0          8.456674       7.999967      7.962834   \n",
       "9        2.0          1.731718       2.000039      2.025203   \n",
       "10       8.0          8.025552       8.000000      7.999484   \n",
       "11       2.0          1.897942       2.000000      2.008566   \n",
       "12       7.0          7.364607       6.999967      6.966460   \n",
       "\n",
       "    conjugate_gradient  \n",
       "0             1.000000  \n",
       "1             3.999995  \n",
       "2             0.999996  \n",
       "3             6.999998  \n",
       "4             2.999997  \n",
       "5             3.999997  \n",
       "6             5.999998  \n",
       "7             0.999997  \n",
       "8             8.000001  \n",
       "9             2.000001  \n",
       "10            8.000000  \n",
       "11            2.000000  \n",
       "12            6.999996  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"solution\":x_solution.flatten(),\"steepest_descent\":x1.flatten(),\"newton_method\":x2.flatten(),\"quasi_newton\":x3.flatten(),\"conjugate_gradient\":x4.flatten()}\n",
    "pd.DataFrame(data,columns=[\"solution\",\"steepest_descent\",\"newton_method\",\"quasi_newton\",\"conjugate_gradient\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36aab01-625c-48c6-abdc-23e48449c3ae",
   "metadata": {},
   "source": [
    "# 4) Matrix 15x15:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8a9f318f-e32f-44c2-a69c-1e00b97d8d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 15\n",
    "x_solution, A, b = problem(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dfe7e4a5-4cc2-4bad-b01f-eb7a7f2db0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:[0] Loss: 3655.13\n",
      "iteration:[100] Loss: 20.24\n",
      "iteration:[200] Loss: 2.94\n",
      "iteration:[300] Loss: 1.04\n",
      "iteration:[400] Loss: 0.4\n"
     ]
    }
   ],
   "source": [
    "x1 = steepest_descent(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6e12d0df-1d98-4f24-ab31-a0ac584730f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:[0] Loss: 4651.85\n",
      "iteration:[4] Loss: 2231.49\n",
      "iteration:[8] Loss: 1070.44\n",
      "iteration:[12] Loss: 513.49\n",
      "iteration:[16] Loss: 246.32\n",
      "iteration:[20] Loss: 118.16\n",
      "iteration:[24] Loss: 56.68\n",
      "iteration:[28] Loss: 27.19\n",
      "iteration:[32] Loss: 13.04\n",
      "iteration:[36] Loss: 6.26\n",
      "iteration:[40] Loss: 3.0\n",
      "iteration:[44] Loss: 1.44\n",
      "iteration:[48] Loss: 0.69\n",
      "iteration:[52] Loss: 0.33\n",
      "iteration:[56] Loss: 0.16\n"
     ]
    }
   ],
   "source": [
    "x2 = newton_method(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e55bed64-9c7d-4dda-9c7d-e8d73136bbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Loss: 8579.1\n",
      "[4] Loss: 8425.42\n",
      "[8] Loss: 7050.66\n",
      "[12] Loss: 5921.98\n",
      "[16] Loss: 3864.49\n",
      "[20] Loss: 1811.04\n",
      "[24] Loss: 868.75\n",
      "[28] Loss: 416.73\n",
      "[32] Loss: 199.89\n",
      "[36] Loss: 95.87\n",
      "[40] Loss: 45.96\n",
      "[44] Loss: 22.01\n",
      "[48] Loss: 10.5\n",
      "[52] Loss: 4.96\n",
      "[56] Loss: 2.27\n",
      "[60] Loss: 0.94\n",
      "[64] Loss: 0.19\n"
     ]
    }
   ],
   "source": [
    "x3 = quasi_newton(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c2a8994a-8b7e-4312-9957-a2725999c2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Loss: 798.42\n",
      "[1] Loss: 413.06\n",
      "[2] Loss: 325.38\n",
      "[3] Loss: 113.85\n",
      "[4] Loss: 46.1\n",
      "[5] Loss: 37.31\n",
      "[6] Loss: 13.1\n",
      "[7] Loss: 12.1\n",
      "[8] Loss: 9.45\n",
      "[9] Loss: 18.16\n",
      "[10] Loss: 6.45\n",
      "[11] Loss: 3.88\n",
      "[12] Loss: 2.62\n",
      "[13] Loss: 0.09\n"
     ]
    }
   ],
   "source": [
    "x4 = conjugate_gradient(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9abc47d8-823e-40ab-ab79-2f01027f77c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solution</th>\n",
       "      <th>steepest_descent</th>\n",
       "      <th>newton_method</th>\n",
       "      <th>quasi_newton</th>\n",
       "      <th>conjugate_gradient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.972867</td>\n",
       "      <td>5.000016</td>\n",
       "      <td>4.997277</td>\n",
       "      <td>5.004073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.995273</td>\n",
       "      <td>2.999984</td>\n",
       "      <td>2.999356</td>\n",
       "      <td>2.999964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.923168</td>\n",
       "      <td>5.000016</td>\n",
       "      <td>4.989368</td>\n",
       "      <td>5.022286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.943908</td>\n",
       "      <td>5.999918</td>\n",
       "      <td>5.992160</td>\n",
       "      <td>6.015671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.746962</td>\n",
       "      <td>5.000016</td>\n",
       "      <td>4.967402</td>\n",
       "      <td>5.068848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.405729</td>\n",
       "      <td>5.999984</td>\n",
       "      <td>6.054502</td>\n",
       "      <td>5.887173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.042471</td>\n",
       "      <td>3.000066</td>\n",
       "      <td>3.005969</td>\n",
       "      <td>2.986897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.197907</td>\n",
       "      <td>5.000016</td>\n",
       "      <td>5.027526</td>\n",
       "      <td>4.941291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.934235</td>\n",
       "      <td>2.000016</td>\n",
       "      <td>1.990350</td>\n",
       "      <td>2.020996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.959107</td>\n",
       "      <td>6.999918</td>\n",
       "      <td>6.994432</td>\n",
       "      <td>7.014045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986274</td>\n",
       "      <td>1.000115</td>\n",
       "      <td>0.998948</td>\n",
       "      <td>1.004534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.048982</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.006539</td>\n",
       "      <td>3.986522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.808591</td>\n",
       "      <td>5.999984</td>\n",
       "      <td>5.972109</td>\n",
       "      <td>6.058113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8.0</td>\n",
       "      <td>7.974449</td>\n",
       "      <td>7.999984</td>\n",
       "      <td>7.996828</td>\n",
       "      <td>8.005301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.012705</td>\n",
       "      <td>3.000033</td>\n",
       "      <td>3.000928</td>\n",
       "      <td>2.997866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    solution  steepest_descent  newton_method  quasi_newton  \\\n",
       "0        5.0          4.972867       5.000016      4.997277   \n",
       "1        3.0          2.995273       2.999984      2.999356   \n",
       "2        5.0          4.923168       5.000016      4.989368   \n",
       "3        6.0          5.943908       5.999918      5.992160   \n",
       "4        5.0          4.746962       5.000016      4.967402   \n",
       "5        6.0          6.405729       5.999984      6.054502   \n",
       "6        3.0          3.042471       3.000066      3.005969   \n",
       "7        5.0          5.197907       5.000016      5.027526   \n",
       "8        2.0          1.934235       2.000016      1.990350   \n",
       "9        7.0          6.959107       6.999918      6.994432   \n",
       "10       1.0          0.986274       1.000115      0.998948   \n",
       "11       4.0          4.048982       4.000000      4.006539   \n",
       "12       6.0          5.808591       5.999984      5.972109   \n",
       "13       8.0          7.974449       7.999984      7.996828   \n",
       "14       3.0          3.012705       3.000033      3.000928   \n",
       "\n",
       "    conjugate_gradient  \n",
       "0             5.004073  \n",
       "1             2.999964  \n",
       "2             5.022286  \n",
       "3             6.015671  \n",
       "4             5.068848  \n",
       "5             5.887173  \n",
       "6             2.986897  \n",
       "7             4.941291  \n",
       "8             2.020996  \n",
       "9             7.014045  \n",
       "10            1.004534  \n",
       "11            3.986522  \n",
       "12            6.058113  \n",
       "13            8.005301  \n",
       "14            2.997866  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"solution\":x_solution.flatten(),\"steepest_descent\":x1.flatten(),\"newton_method\":x2.flatten(),\"quasi_newton\":x3.flatten(),\"conjugate_gradient\":x4.flatten()}\n",
    "pd.DataFrame(data,columns=[\"solution\",\"steepest_descent\",\"newton_method\",\"quasi_newton\",\"conjugate_gradient\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f88eb-8340-47c8-82d1-9b96e002f7f7",
   "metadata": {},
   "source": [
    "# 5) Matrix 17x17:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1004ccb4-bd02-4c07-95de-4c8d87097531",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 17\n",
    "x_solution, A, b = problem(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "33c56f26-16cd-40af-bce7-028bd8f2771b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:[0] Loss: 1575.77\n",
      "iteration:[100] Loss: 33.75\n",
      "iteration:[200] Loss: 12.71\n",
      "iteration:[300] Loss: 14.91\n",
      "iteration:[400] Loss: 7.84\n",
      "iteration:[500] Loss: 4.27\n",
      "iteration:[600] Loss: 2.76\n",
      "iteration:[700] Loss: 2.2\n",
      "iteration:[800] Loss: 1.53\n",
      "iteration:[900] Loss: 0.96\n",
      "iteration:[1000] Loss: 0.73\n",
      "iteration:[1100] Loss: 0.65\n",
      "iteration:[1200] Loss: 1.49\n",
      "iteration:[1300] Loss: 0.51\n",
      "iteration:[1400] Loss: 0.52\n",
      "iteration:[1500] Loss: 1.29\n",
      "iteration:[1600] Loss: 0.59\n",
      "iteration:[1700] Loss: 0.49\n",
      "iteration:[1800] Loss: 0.42\n",
      "iteration:[1900] Loss: 0.45\n",
      "iteration:[2000] Loss: 0.81\n",
      "iteration:[2100] Loss: 0.41\n",
      "iteration:[2200] Loss: 0.55\n",
      "iteration:[2300] Loss: 0.46\n",
      "iteration:[2400] Loss: 0.4\n",
      "iteration:[2500] Loss: 0.54\n",
      "iteration:[2600] Loss: 0.38\n",
      "iteration:[2700] Loss: 0.63\n",
      "iteration:[2800] Loss: 0.52\n",
      "iteration:[2900] Loss: 0.44\n",
      "iteration:[3000] Loss: 0.37\n",
      "iteration:[3100] Loss: 0.51\n",
      "iteration:[3200] Loss: 0.43\n",
      "iteration:[3300] Loss: 1.08\n",
      "iteration:[3400] Loss: 0.49\n",
      "iteration:[3500] Loss: 0.41\n",
      "iteration:[3600] Loss: 0.36\n",
      "iteration:[3700] Loss: 0.49\n",
      "iteration:[3800] Loss: 0.41\n",
      "iteration:[3900] Loss: 0.35\n",
      "iteration:[4000] Loss: 0.85\n",
      "iteration:[4100] Loss: 0.39\n",
      "iteration:[4200] Loss: 0.34\n",
      "iteration:[4300] Loss: 0.46\n",
      "iteration:[4400] Loss: 0.39\n",
      "iteration:[4500] Loss: 0.33\n",
      "iteration:[4600] Loss: 0.36\n",
      "iteration:[4700] Loss: 0.32\n",
      "iteration:[4800] Loss: 0.53\n",
      "iteration:[4900] Loss: 0.44\n",
      "iteration:[5000] Loss: 0.37\n",
      "iteration:[5100] Loss: 0.32\n",
      "iteration:[5200] Loss: 0.43\n",
      "iteration:[5300] Loss: 0.36\n",
      "iteration:[5400] Loss: 0.91\n",
      "iteration:[5500] Loss: 0.76\n",
      "iteration:[5600] Loss: 0.35\n",
      "iteration:[5700] Loss: 0.3\n",
      "iteration:[5800] Loss: 0.41\n",
      "iteration:[5900] Loss: 0.34\n",
      "iteration:[6000] Loss: 0.3\n",
      "iteration:[6100] Loss: 0.32\n",
      "iteration:[6200] Loss: 0.29\n",
      "iteration:[6300] Loss: 0.47\n",
      "iteration:[6400] Loss: 0.39\n",
      "iteration:[6500] Loss: 0.33\n",
      "iteration:[6600] Loss: 0.28\n",
      "iteration:[6700] Loss: 0.39\n",
      "iteration:[6800] Loss: 0.32\n",
      "iteration:[6900] Loss: 0.28\n",
      "iteration:[7000] Loss: 0.67\n",
      "iteration:[7100] Loss: 0.54\n",
      "iteration:[7200] Loss: 0.27\n",
      "iteration:[7300] Loss: 0.37\n",
      "iteration:[7400] Loss: 0.31\n",
      "iteration:[7500] Loss: 0.27\n",
      "iteration:[7600] Loss: 0.36\n",
      "iteration:[7700] Loss: 0.3\n",
      "iteration:[7800] Loss: 0.77\n",
      "iteration:[7900] Loss: 0.64\n",
      "iteration:[8000] Loss: 0.29\n",
      "iteration:[8100] Loss: 0.26\n",
      "iteration:[8200] Loss: 0.35\n",
      "iteration:[8300] Loss: 0.29\n",
      "iteration:[8400] Loss: 0.25\n",
      "iteration:[8500] Loss: 0.34\n",
      "iteration:[8600] Loss: 0.29\n",
      "iteration:[8700] Loss: 0.73\n",
      "iteration:[8800] Loss: 0.33\n",
      "iteration:[8900] Loss: 0.28\n",
      "iteration:[9000] Loss: 0.24\n",
      "iteration:[9100] Loss: 0.33\n",
      "iteration:[9200] Loss: 0.28\n",
      "iteration:[9300] Loss: 0.24\n",
      "iteration:[9400] Loss: 0.33\n",
      "iteration:[9500] Loss: 0.23\n",
      "iteration:[9600] Loss: 0.69\n",
      "iteration:[9700] Loss: 0.31\n",
      "iteration:[9800] Loss: 0.26\n",
      "iteration:[9900] Loss: 0.23\n",
      "iteration:[10000] Loss: 0.31\n",
      "iteration:[10100] Loss: 0.26\n",
      "iteration:[10200] Loss: 0.22\n",
      "iteration:[10300] Loss: 0.31\n",
      "iteration:[10400] Loss: 0.26\n",
      "iteration:[10500] Loss: 0.65\n",
      "iteration:[10600] Loss: 0.3\n",
      "iteration:[10700] Loss: 0.25\n",
      "iteration:[10800] Loss: 0.22\n",
      "iteration:[10900] Loss: 0.29\n",
      "iteration:[11000] Loss: 0.25\n",
      "iteration:[11100] Loss: 0.21\n",
      "iteration:[11200] Loss: 0.29\n",
      "iteration:[11300] Loss: 0.24\n",
      "iteration:[11400] Loss: 0.62\n",
      "iteration:[11500] Loss: 0.51\n",
      "iteration:[11600] Loss: 0.24\n",
      "iteration:[11700] Loss: 0.21\n",
      "iteration:[11800] Loss: 0.28\n",
      "iteration:[11900] Loss: 0.24\n",
      "iteration:[12000] Loss: 0.2\n",
      "iteration:[12100] Loss: 0.28\n",
      "iteration:[12200] Loss: 0.23\n",
      "iteration:[12300] Loss: 0.2\n",
      "iteration:[12400] Loss: 0.22\n",
      "iteration:[12500] Loss: 0.39\n",
      "iteration:[12600] Loss: 0.32\n",
      "iteration:[12700] Loss: 0.27\n",
      "iteration:[12800] Loss: 0.22\n",
      "iteration:[12900] Loss: 0.19\n",
      "iteration:[13000] Loss: 0.26\n",
      "iteration:[13100] Loss: 0.22\n",
      "iteration:[13200] Loss: 0.19\n",
      "iteration:[13300] Loss: 0.21\n",
      "iteration:[13400] Loss: 0.19\n",
      "iteration:[13500] Loss: 0.31\n",
      "iteration:[13600] Loss: 0.25\n",
      "iteration:[13700] Loss: 0.21\n",
      "iteration:[13800] Loss: 0.18\n",
      "iteration:[13900] Loss: 0.25\n",
      "iteration:[14000] Loss: 0.21\n",
      "iteration:[14100] Loss: 0.18\n",
      "iteration:[14200] Loss: 0.25\n",
      "iteration:[14300] Loss: 0.21\n",
      "iteration:[14400] Loss: 0.53\n",
      "iteration:[14500] Loss: 0.44\n",
      "iteration:[14600] Loss: 0.35\n",
      "iteration:[14700] Loss: 0.18\n",
      "iteration:[14800] Loss: 0.24\n",
      "iteration:[14900] Loss: 0.2\n",
      "iteration:[15000] Loss: 0.17\n",
      "iteration:[15100] Loss: 0.24\n",
      "iteration:[15200] Loss: 0.2\n",
      "iteration:[15300] Loss: 0.17\n",
      "iteration:[15400] Loss: 0.19\n",
      "iteration:[15500] Loss: 0.17\n",
      "iteration:[15600] Loss: 0.28\n",
      "iteration:[15700] Loss: 0.23\n",
      "iteration:[15800] Loss: 0.19\n",
      "iteration:[15900] Loss: 0.17\n",
      "iteration:[16000] Loss: 0.23\n",
      "iteration:[16100] Loss: 0.19\n",
      "iteration:[16200] Loss: 0.16\n",
      "iteration:[16300] Loss: 0.23\n",
      "iteration:[16400] Loss: 0.19\n",
      "iteration:[16500] Loss: 0.17\n",
      "iteration:[16600] Loss: 0.4\n",
      "iteration:[16700] Loss: 0.32\n",
      "iteration:[16800] Loss: 0.16\n",
      "iteration:[16900] Loss: 0.22\n",
      "iteration:[17000] Loss: 0.18\n",
      "iteration:[17100] Loss: 0.16\n",
      "iteration:[17200] Loss: 0.22\n",
      "iteration:[17300] Loss: 0.18\n",
      "iteration:[17400] Loss: 0.16\n",
      "iteration:[17500] Loss: 0.21\n",
      "iteration:[17600] Loss: 0.15\n",
      "iteration:[17700] Loss: 0.45\n",
      "iteration:[17800] Loss: 0.21\n",
      "iteration:[17900] Loss: 0.17\n",
      "iteration:[18000] Loss: 0.15\n",
      "iteration:[18100] Loss: 0.21\n",
      "iteration:[18200] Loss: 0.17\n",
      "iteration:[18300] Loss: 0.15\n",
      "iteration:[18400] Loss: 0.2\n",
      "iteration:[18500] Loss: 0.17\n",
      "iteration:[18600] Loss: 0.15\n",
      "iteration:[18700] Loss: 0.16\n",
      "iteration:[18800] Loss: 0.29\n",
      "iteration:[18900] Loss: 0.24\n",
      "iteration:[19000] Loss: 0.2\n",
      "iteration:[19100] Loss: 0.16\n",
      "iteration:[19200] Loss: 0.14\n",
      "iteration:[19300] Loss: 0.19\n",
      "iteration:[19400] Loss: 0.16\n",
      "iteration:[19500] Loss: 0.14\n",
      "iteration:[19600] Loss: 0.19\n",
      "iteration:[19700] Loss: 0.16\n",
      "iteration:[19800] Loss: 0.14\n",
      "iteration:[19900] Loss: 0.34\n",
      "iteration:[20000] Loss: 0.27\n",
      "iteration:[20100] Loss: 0.14\n",
      "iteration:[20200] Loss: 0.19\n",
      "iteration:[20300] Loss: 0.16\n",
      "iteration:[20400] Loss: 0.14\n",
      "iteration:[20500] Loss: 0.19\n",
      "iteration:[20600] Loss: 0.16\n",
      "iteration:[20700] Loss: 0.13\n",
      "iteration:[20800] Loss: 0.18\n",
      "iteration:[20900] Loss: 0.13\n",
      "iteration:[21000] Loss: 0.39\n",
      "iteration:[21100] Loss: 0.32\n",
      "iteration:[21200] Loss: 0.15\n",
      "iteration:[21300] Loss: 0.13\n",
      "iteration:[21400] Loss: 0.18\n",
      "iteration:[21500] Loss: 0.15\n",
      "iteration:[21600] Loss: 0.13\n",
      "iteration:[21700] Loss: 0.18\n",
      "iteration:[21800] Loss: 0.15\n",
      "iteration:[21900] Loss: 0.13\n",
      "iteration:[22000] Loss: 0.14\n",
      "iteration:[22100] Loss: 0.12\n",
      "iteration:[22200] Loss: 0.21\n",
      "iteration:[22300] Loss: 0.17\n",
      "iteration:[22400] Loss: 0.14\n",
      "iteration:[22500] Loss: 0.12\n",
      "iteration:[22600] Loss: 0.17\n",
      "iteration:[22700] Loss: 0.14\n",
      "iteration:[22800] Loss: 0.12\n",
      "iteration:[22900] Loss: 0.17\n",
      "iteration:[23000] Loss: 0.14\n",
      "iteration:[23100] Loss: 0.12\n",
      "iteration:[23200] Loss: 0.13\n",
      "iteration:[23300] Loss: 0.24\n",
      "iteration:[23400] Loss: 0.2\n",
      "iteration:[23500] Loss: 0.16\n",
      "iteration:[23600] Loss: 0.14\n",
      "iteration:[23700] Loss: 0.12\n",
      "iteration:[23800] Loss: 0.16\n",
      "iteration:[23900] Loss: 0.13\n",
      "iteration:[24000] Loss: 0.12\n",
      "iteration:[24100] Loss: 0.16\n",
      "iteration:[24200] Loss: 0.13\n",
      "iteration:[24300] Loss: 0.12\n",
      "iteration:[24400] Loss: 0.12\n",
      "iteration:[24500] Loss: 0.22\n",
      "iteration:[24600] Loss: 0.11\n",
      "iteration:[24700] Loss: 0.15\n",
      "iteration:[24800] Loss: 0.13\n",
      "iteration:[24900] Loss: 0.11\n",
      "iteration:[25000] Loss: 0.15\n",
      "iteration:[25100] Loss: 0.13\n",
      "iteration:[25200] Loss: 0.11\n",
      "iteration:[25300] Loss: 0.15\n",
      "iteration:[25400] Loss: 0.13\n",
      "iteration:[25500] Loss: 0.32\n",
      "iteration:[25600] Loss: 0.27\n",
      "iteration:[25700] Loss: 0.21\n",
      "iteration:[25800] Loss: 0.11\n",
      "iteration:[25900] Loss: 0.14\n",
      "iteration:[26000] Loss: 0.12\n",
      "iteration:[26100] Loss: 0.11\n",
      "iteration:[26200] Loss: 0.14\n",
      "iteration:[26300] Loss: 0.12\n",
      "iteration:[26400] Loss: 0.1\n",
      "iteration:[26500] Loss: 0.14\n",
      "iteration:[26600] Loss: 0.12\n",
      "iteration:[26700] Loss: 0.3\n",
      "iteration:[26800] Loss: 0.25\n",
      "iteration:[26900] Loss: 0.2\n",
      "iteration:[27000] Loss: 0.1\n"
     ]
    }
   ],
   "source": [
    "x1 = steepest_descent(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "54279a38-d582-4776-92e1-ebae74aaad21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:[0] Loss: 11045.65\n",
      "iteration:[4] Loss: 5298.59\n",
      "iteration:[8] Loss: 2541.73\n",
      "iteration:[12] Loss: 1219.27\n",
      "iteration:[16] Loss: 584.88\n",
      "iteration:[20] Loss: 280.57\n",
      "iteration:[24] Loss: 134.59\n",
      "iteration:[28] Loss: 64.56\n",
      "iteration:[32] Loss: 30.97\n",
      "iteration:[36] Loss: 14.86\n",
      "iteration:[40] Loss: 7.13\n",
      "iteration:[44] Loss: 3.42\n",
      "iteration:[48] Loss: 1.64\n",
      "iteration:[52] Loss: 0.79\n",
      "iteration:[56] Loss: 0.38\n",
      "iteration:[60] Loss: 0.18\n",
      "iteration:[64] Loss: 0.09\n"
     ]
    }
   ],
   "source": [
    "x2 = newton_method(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5a16b77b-9ff7-44bb-a712-777d677b1be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Loss: 10462.02\n",
      "[4] Loss: 10342.58\n",
      "[8] Loss: 8638.72\n",
      "[12] Loss: 7616.97\n",
      "[16] Loss: 5193.01\n",
      "[20] Loss: 2711.57\n",
      "[24] Loss: 1300.56\n",
      "[28] Loss: 623.64\n",
      "[32] Loss: 298.83\n",
      "[36] Loss: 142.89\n",
      "[40] Loss: 67.94\n",
      "[44] Loss: 31.8\n",
      "[48] Loss: 14.23\n",
      "[52] Loss: 5.55\n",
      "[56] Loss: 0.77\n"
     ]
    }
   ],
   "source": [
    "x3 = quasi_newton(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "949105bd-e755-4fa3-8c61-7c6e2fadc4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Loss: 1403.87\n",
      "[1] Loss: 417.19\n",
      "[2] Loss: 202.58\n",
      "[3] Loss: 121.89\n",
      "[4] Loss: 76.27\n",
      "[5] Loss: 45.86\n",
      "[6] Loss: 51.79\n",
      "[7] Loss: 24.49\n",
      "[8] Loss: 16.1\n",
      "[9] Loss: 45.2\n",
      "[10] Loss: 7.67\n",
      "[11] Loss: 4.45\n",
      "[12] Loss: 4.14\n",
      "[13] Loss: 2.68\n",
      "[14] Loss: 0.56\n",
      "[15] Loss: 0.38\n",
      "[16] Loss: 2.66\n",
      "[17] Loss: 0.07\n"
     ]
    }
   ],
   "source": [
    "x4 = conjugate_gradient(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b816cc81-08f2-4885-b039-8e8b2986626d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solution</th>\n",
       "      <th>steepest_descent</th>\n",
       "      <th>newton_method</th>\n",
       "      <th>quasi_newton</th>\n",
       "      <th>conjugate_gradient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.810418</td>\n",
       "      <td>6.999993</td>\n",
       "      <td>6.949821</td>\n",
       "      <td>7.037101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852817</td>\n",
       "      <td>1.000046</td>\n",
       "      <td>0.961532</td>\n",
       "      <td>1.015218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.554739</td>\n",
       "      <td>6.999967</td>\n",
       "      <td>6.883746</td>\n",
       "      <td>7.043488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>7.596306</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.899319</td>\n",
       "      <td>7.910738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.925457</td>\n",
       "      <td>6.999961</td>\n",
       "      <td>6.981610</td>\n",
       "      <td>6.978078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.611392</td>\n",
       "      <td>1.000013</td>\n",
       "      <td>1.160793</td>\n",
       "      <td>0.908806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.092325</td>\n",
       "      <td>3.000033</td>\n",
       "      <td>3.020696</td>\n",
       "      <td>3.083993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>7.914227</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.973744</td>\n",
       "      <td>8.113663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.185307</td>\n",
       "      <td>6.999961</td>\n",
       "      <td>6.794141</td>\n",
       "      <td>6.892527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.410660</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.105900</td>\n",
       "      <td>0.995872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.070378</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.017743</td>\n",
       "      <td>4.010464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.190207</td>\n",
       "      <td>2.000039</td>\n",
       "      <td>2.045830</td>\n",
       "      <td>2.085818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.432099</td>\n",
       "      <td>5.000013</td>\n",
       "      <td>5.109329</td>\n",
       "      <td>5.053033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.703848</td>\n",
       "      <td>6.999993</td>\n",
       "      <td>6.923597</td>\n",
       "      <td>7.003877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.290803</td>\n",
       "      <td>7.999993</td>\n",
       "      <td>8.079878</td>\n",
       "      <td>7.864154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.785187</td>\n",
       "      <td>1.000033</td>\n",
       "      <td>1.198231</td>\n",
       "      <td>1.108251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.471884</td>\n",
       "      <td>3.000013</td>\n",
       "      <td>2.866287</td>\n",
       "      <td>2.937495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    solution  steepest_descent  newton_method  quasi_newton  \\\n",
       "0        7.0          6.810418       6.999993      6.949821   \n",
       "1        1.0          0.852817       1.000046      0.961532   \n",
       "2        7.0          6.554739       6.999967      6.883746   \n",
       "3        8.0          7.596306       8.000000      7.899319   \n",
       "4        7.0          6.925457       6.999961      6.981610   \n",
       "5        1.0          1.611392       1.000013      1.160793   \n",
       "6        3.0          3.092325       3.000033      3.020696   \n",
       "7        8.0          7.914227       8.000000      7.973744   \n",
       "8        7.0          6.185307       6.999961      6.794141   \n",
       "9        1.0          1.410660       1.000000      1.105900   \n",
       "10       4.0          4.070378       4.000000      4.017743   \n",
       "11       2.0          2.190207       2.000039      2.045830   \n",
       "12       5.0          5.432099       5.000013      5.109329   \n",
       "13       7.0          6.703848       6.999993      6.923597   \n",
       "14       8.0          8.290803       7.999993      8.079878   \n",
       "15       1.0          1.785187       1.000033      1.198231   \n",
       "16       3.0          2.471884       3.000013      2.866287   \n",
       "\n",
       "    conjugate_gradient  \n",
       "0             7.037101  \n",
       "1             1.015218  \n",
       "2             7.043488  \n",
       "3             7.910738  \n",
       "4             6.978078  \n",
       "5             0.908806  \n",
       "6             3.083993  \n",
       "7             8.113663  \n",
       "8             6.892527  \n",
       "9             0.995872  \n",
       "10            4.010464  \n",
       "11            2.085818  \n",
       "12            5.053033  \n",
       "13            7.003877  \n",
       "14            7.864154  \n",
       "15            1.108251  \n",
       "16            2.937495  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"solution\":x_solution.flatten(),\"steepest_descent\":x1.flatten(),\"newton_method\":x2.flatten(),\"quasi_newton\":x3.flatten(),\"conjugate_gradient\":x4.flatten()}\n",
    "pd.DataFrame(data,columns=[\"solution\",\"steepest_descent\",\"newton_method\",\"quasi_newton\",\"conjugate_gradient\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89902f62-8fbd-45aa-b9d1-5be8c02ab0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
